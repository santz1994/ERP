# Logstash Configuration for Quty Karunia ERP
# Processes logs from FastAPI backend, PostgreSQL, nginx

input {
  # TCP input for JSON logs
  tcp {
    port => 5000
    codec => json
    type => "backend"
  }

  # Syslog input for system logs
  udp {
    port => 514
    type => "syslog"
  }

  # File input for PostgreSQL logs (if needed)
  file {
    path => "/var/log/postgresql/postgresql.log"
    type => "postgres"
    start_position => "beginning"
  }

  # File input for nginx logs
  file {
    path => "/var/log/nginx/access.log"
    type => "nginx"
    start_position => "beginning"
  }
}

filter {
  # Parse backend logs (FastAPI)
  if [type] == "backend" {
    # Already JSON, minimal parsing needed
    mutate {
      add_field => { "[@metadata][index_name]" => "erp-backend-%{+YYYY.MM.dd}" }
    }
  }

  # Parse PostgreSQL logs
  if [type] == "postgres" {
    grok {
      match => {
        "message" => "%{TIMESTAMP_ISO8601:timestamp}\s+\[%{DATA:postgres_pid}\]\s+%{WORD:level}:\s+%{GREEDYDATA:log_message}"
      }
    }
    mutate {
      add_field => { "[@metadata][index_name]" => "erp-postgres-%{+YYYY.MM.dd}" }
    }
  }

  # Parse nginx logs
  if [type] == "nginx" {
    grok {
      match => {
        "message" => "%{COMBINEDAPACHELOG}"
      }
    }
    
    # Parse response times
    if [rt] {
      mutate {
        convert => { "rt" => "float" }
        add_field => { "response_time_ms" => "%{rt}" }
      }
    }

    # Parse status code range
    if [response] {
      if [response] =~ /^2/ {
        mutate { add_field => { "status_category" => "2xx" } }
      } else if [response] =~ /^3/ {
        mutate { add_field => { "status_category" => "3xx" } }
      } else if [response] =~ /^4/ {
        mutate { add_field => { "status_category" => "4xx" } }
      } else if [response] =~ /^5/ {
        mutate { add_field => { "status_category" => "5xx" } }
      }
    }

    mutate {
      add_field => { "[@metadata][index_name]" => "erp-nginx-%{+YYYY.MM.dd}" }
    }
  }

  # Parse syslog
  if [type] == "syslog" {
    grok {
      match => { "message" => "%{SYSLOGLINE}" }
    }
    mutate {
      add_field => { "[@metadata][index_name]" => "erp-syslog-%{+YYYY.MM.dd}" }
    }
  }

  # Add common fields
  mutate {
    add_field => { "environment" => "production" }
    add_field => { "application" => "quty-karunia-erp" }
    add_field => { "[@metadata][environment]" => "production" }
  }

  # Alert on critical errors
  if [level] == "CRITICAL" or [level] == "ALERT" {
    mutate {
      add_field => { "alert_level" => "critical" }
    }
  } else if [level] == "ERROR" or [level] == "SEVERE" {
    mutate {
      add_field => { "alert_level" => "error" }
    }
  } else if [level] == "WARNING" {
    mutate {
      add_field => { "alert_level" => "warning" }
    }
  }

  # Extract API endpoint from backend logs
  if [type] == "backend" and [request_path] {
    mutate {
      gsub => [ "request_path", "^/api/v1", "" ]
      add_field => { "endpoint" => "%{request_path}" }
    }
  }

  # Extract department and workflow info from backend logs
  if [type] == "backend" and [message] =~ /department|workflow|qt09/ {
    if [message] =~ /cutting/i {
      mutate { add_field => { "department" => "CUTTING" } }
    } else if [message] =~ /sewing/i {
      mutate { add_field => { "department" => "SEWING" } }
    } else if [message] =~ /finishing/i {
      mutate { add_field => { "department" => "FINISHING" } }
    } else if [message] =~ /packing/i {
      mutate { add_field => { "department" => "PACKING" } }
    }

    if [message] =~ /qt09|handshake|line_clearance/i {
      mutate { add_field => { "protocol" => "QT-09" } }
    }

    if [message] =~ /metal_detector|metal detection/i {
      mutate { add_field => { "quality_check" => "metal_detector" } }
    }
  }

  # Standardize timestamp
  date {
    match => ["timestamp", "ISO8601", "YYYY-MM-dd HH:mm:ss.SSS", "YYYY-MM-dd HH:mm:ss"]
    target => "@timestamp"
  }

  # Clean up extra fields
  mutate {
    remove_field => ["headers", "raw_request_headers", "@version"]
  }
}

output {
  # Send to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "%{[@metadata][index_name]}"
    document_type => "_doc"
    manage_template => true
    template_name => "erp"
    template_overwrite => false
    template => {
      "template": "erp-*",
      "settings": {
        "number_of_shards": 2,
        "number_of_replicas": 1,
        "index.refresh_interval": "30s"
      },
      "mappings": {
        "properties": {
          "timestamp": {
            "type": "date"
          },
          "level": {
            "type": "keyword"
          },
          "department": {
            "type": "keyword"
          },
          "protocol": {
            "type": "keyword"
          },
          "quality_check": {
            "type": "keyword"
          },
          "status_category": {
            "type": "keyword"
          },
          "response_time_ms": {
            "type": "float"
          },
          "message": {
            "type": "text",
            "analyzer": "standard"
          },
          "alert_level": {
            "type": "keyword"
          }
        }
      }
    }
  }

  # Debug output to stdout
  if [@metadata][index_name] {
    stdout {
      codec => rubydebug
    }
  }

  # Send critical alerts to stdout for alerting
  if [alert_level] == "critical" {
    stdout {
      message => "ðŸš¨ CRITICAL ALERT: [%{[@metadata][index_name]}] %{message}"
    }
  }
}

